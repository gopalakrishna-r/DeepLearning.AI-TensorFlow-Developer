{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
<<<<<<< HEAD
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zX4Kg8DUTKWO"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
=======
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "# you may not use this file except in compliance with the License.\r\n",
        "# You may obtain a copy of the License at\r\n",
        "#\r\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\r\n",
        "#\r\n",
        "# Unless required by applicable law or agreed to in writing, software\r\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "# See the License for the specific language governing permissions and\r\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": 2,
<<<<<<< HEAD
=======
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0\n"
          ]
        }
      ],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "56XEQOGknrAk",
        "outputId": "0f446cf8-5d23-4dab-9783-08a1d284e3a3"
<<<<<<< HEAD
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": 3,
<<<<<<< HEAD
=======
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "def plot_series(time, series, format=\"-\", start=0, end=None):\r\n",
        "    plt.plot(time[start:end], series[start:end], format)\r\n",
        "    plt.xlabel(\"Time\")\r\n",
        "    plt.ylabel(\"Value\")\r\n",
        "    plt.grid(True)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sLl52leVp5wU"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": 4,
<<<<<<< HEAD
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tP7oqUdkk0gY"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-4-00b3ead04bdd>, line 2)",
          "output_type": "error",
=======
      "source": [
        "path_to_file = tf.keras.utils.get_file('daily-min-temperatures.csv', 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-4-00b3ead04bdd>, line 2)",
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-00b3ead04bdd>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv \\\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
<<<<<<< HEAD
      "source": [
        "path_to_file = tf.keras.utils.get_file('daily-min-temperatures.csv', 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv')"
      ]
=======
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tP7oqUdkk0gY"
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "import csv\r\n",
        "time_step = []\r\n",
        "temps = []\r\n",
        "\r\n",
        "with open(path_to_file) as csvfile:\r\n",
        "  reader = csv.reader(csvfile, delimiter=',')\r\n",
        "  next(reader)\r\n",
        "  step=0\r\n",
        "  for row in reader:\r\n",
        "    temps.append(float(row[1]))\r\n",
        "    time_step.append(step)\r\n",
        "    step = step + 1\r\n",
        "\r\n",
        "series = np.array(temps)\r\n",
        "time = np.array(time_step)\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plot_series(time, series)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "colab_type": "code",
        "id": "NcG9r1eClbTh",
        "outputId": "9c9c679a-f57c-4b0d-8b2a-f98a8e6fb9e3"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "time_step = []\n",
        "temps = []\n",
        "\n",
        "with open(path_to_file) as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "  next(reader)\n",
        "  step=0\n",
        "  for row in reader:\n",
        "    temps.append(float(row[1]))\n",
        "    time_step.append(step)\n",
        "    step = step + 1\n",
        "\n",
        "series = np.array(temps)\n",
        "time = np.array(time_step)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "split_time = 2500\r\n",
        "time_train = time[:split_time]\r\n",
        "x_train = series[:split_time]\r\n",
        "time_valid = time[split_time:]\r\n",
        "x_valid = series[split_time:]\r\n",
        "\r\n",
        "window_size = 30\r\n",
        "batch_size = 32\r\n",
        "shuffle_buffer_size = 1000\r\n"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L92YRw_IpCFG"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "split_time = 2500\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 30\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\r\n",
        "    series = tf.expand_dims(series, axis=-1)\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\r\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\r\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\r\n",
        "    ds = ds.shuffle(shuffle_buffer)\r\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\r\n",
        "    print(ds)\r\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lJwUUZscnG38"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    print(ds)\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "def model_forecast(model, series, window_size):\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\r\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\r\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\r\n",
        "    ds = ds.batch(32).prefetch(1)\r\n",
        "    forecast = model.predict(ds)\r\n",
        "    print(ds)\r\n",
        "    return forecast"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4XwGrf-A_wF0"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    print(ds)\n",
        "    return forecast"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "tf.random.set_seed(51)\r\n",
        "np.random.seed(51)\r\n",
        "window_size = 64\r\n",
        "batch_size = 256\r\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\r\n",
        "print(train_set)\r\n",
        "print(x_train.shape)\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\r\n",
        "                      strides=1, padding=\"causal\",\r\n",
        "                      activation=\"relu\",\r\n",
        "                      input_shape=[None, 1]),\r\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\r\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\r\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\r\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\r\n",
        "  tf.keras.layers.Dense(1),\r\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\r\n",
        "])\r\n",
        "\r\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\r\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\r\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\r\n",
        "model.compile(loss=tf.keras.losses.Huber(),\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"mae\"])\r\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])\r\n"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "AclfYY3Mn6Ph",
        "outputId": "dd1fef93-d819-4d56-df20-330169907e16"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "window_size = 64\n",
        "batch_size = 256\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "print(train_set)\n",
        "print(x_train.shape)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])\n"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\r\n",
        "plt.axis([1e-8, 1e-4, 0, 60])"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "colab_type": "code",
        "id": "vVcKmg7Q_7rD",
        "outputId": "5e9b8029-e996-4a2b-e016-666c69865b11"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 60])"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "tf.random.set_seed(51)\r\n",
        "np.random.seed(51)\r\n",
        "train_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=shuffle_buffer_size)\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\r\n",
        "                      strides=1, padding=\"causal\",\r\n",
        "                      activation=\"relu\",\r\n",
        "                      input_shape=[None, 1]),\r\n",
        "  tf.keras.layers.LSTM(60, return_sequences=True),\r\n",
        "  tf.keras.layers.LSTM(60, return_sequences=True),\r\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\r\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\r\n",
        "  tf.keras.layers.Dense(1),\r\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\r\n",
        "model.compile(loss=tf.keras.losses.Huber(),\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"mae\"])\r\n",
        "history = model.fit(train_set,epochs=150)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "QsksvkcXAAgq",
        "outputId": "70263fd4-3c3a-4e93-a451-ee942131e0d4"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "train_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=shuffle_buffer_size)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.LSTM(60, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(60, return_sequences=True),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set,epochs=150)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\r\n",
        "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GaC6NNMRp0lb"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
        "rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "plt.figure(figsize=(10, 6))\r\n",
        "plot_series(time_valid, x_valid)\r\n",
        "plot_series(time_valid, rnn_forecast)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "colab_type": "code",
        "id": "PrktQX3hKYex",
        "outputId": "6f51b039-76a2-4c2d-9f37-c89c6aab20e2"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, rnn_forecast)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "13XrorC5wQoE",
        "outputId": "7f5bda4a-160c-4c0f-e511-a5a1b6945d35"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    },
    {
      "cell_type": "code",
      "execution_count": null,
<<<<<<< HEAD
=======
      "source": [
        "print(rnn_forecast)"
      ],
      "outputs": [],
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "AOVzQXxCwkzP",
        "outputId": "3b3fd11c-f9b3-4cbd-e32d-2d7d22b6ff7f"
<<<<<<< HEAD
      },
      "outputs": [],
      "source": [
        "print(rnn_forecast)"
      ]
=======
      }
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "S+P Week 4 Exercise Answer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
<<<<<<< HEAD
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
=======
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
<<<<<<< HEAD
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c506d1f39c0ed203b21fe551da708c189199b4eb24b97c88a7b4d83b7442f034"
      }
=======
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "360eb45faca1e4dfefc4f13aa9499776008d91528b4d443d812d58097d713eb4"
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
<<<<<<< HEAD
}
=======
}
>>>>>>> 34e6b21abfc5b069204bb7f9f57f96b96d215fc6
